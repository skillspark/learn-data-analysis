{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Project: Popular Data Science Questions \n",
    "\n",
    "## Table of Contents \n",
    "1. [Introduction](#introduction)\n",
    "2. [Stack Exchange](#stack-exchange)\n",
    "3. [Stack Exchange Data Explorer](#sede)\n",
    "4. [Getting the Data](#getting-data)\n",
    "5. [Import the dependencies](#import-the-dependencies)\n",
    "6. [Exploring the Data](#exploring-data)\n",
    "7. [Cleaning the Data](#cleaning-data)\n",
    "8. [Most Used and Most Viewed](#most)\n",
    "9. [Relations Between Tags](#relations-tags)\n",
    "10. [Enter Domain Knowledge](#enter-domain)\n",
    "11. [Just a Fad?](#just-fad)\n",
    "12. [Next Steps](#next-steps)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name = \"introduction\"></a>\n",
    "\n",
    "This is a guided project I completed on the Dataquest learning platform. The focus of this project was to learn new skills related to t.... The goals are to ... the available public data set based on .... The code is written in Python, using ... libraries, and is shown in Jupyter Notebooks.\n",
    "\n",
    "To run these notebooks in your own local dev environent:\n",
    "\n",
    "1. Download the ....ipynb file in this repository and place it in  \"<your_dev_folder>\" folder\n",
    "2. Download the data set ....csv file in this repository and place it in \"<your_dev_folder>/data/...\" folder\n",
    "\n",
    "For the full data set and story behind it, published by ..., go to the following source:\n",
    "\n",
    "### Learn\n",
    "In this course, we explored the business context in which data science happens. You'll now have a chance to apply what you've learned in a more relaxed way. Feel free to explore alternatives to the path we're taking in this project.\n",
    "\n",
    "In this scenario, you're working for a company that creates data science content, be it books, online articles, videos or interactive text-based platforms like Dataquest.\n",
    "\n",
    "You're tasked with figuring out what is best content to write about. Because you took this course, you know that given the lack of instructions there's some leeway in what \"best\" means here.\n",
    "\n",
    "Since you're passionate about helping people learn, you decide to scour the internet in search for the answer to the question \"What is it that people want to learn about in data science?\" (as opposed to determining the most profitable content, for instance).\n",
    "\n",
    "Thinking back to your experience when you first started learning programming, it occurs to you that if you wanted to figure out what programming content to write, you could consult Stack Overflow (a question and answer website about programming) and see what kind of content is more popular.\n",
    "\n",
    "You decide to investigate Stack Overflow a little more and find out that it is part of a question and answer website network called Stack Exchange.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack Exchange <a name = \"stack-exchange\"></a>\n",
    "\n",
    "### Learn\n",
    "\n",
    "Stack Exchange hosts sites on a multitude of fields and subjects, including mathematics, physics, philosophy, and data science! Here's a sample of the most popular sites:\n",
    "\n",
    "\n",
    "Stack Exchange employs a reputation award system for its questions and answers. Each post — each question/answer — is a post that is subject to upvotes and downvotes. This ensures that good posts are easily identifiable.\n",
    "\n",
    "If you're not familiar with Stack Overflow or any other Stack Exchange site, you can check out this tour.\n",
    "\n",
    "Being a multidisciplinary field, there a few Stack Exchange websites there are relevant to our goal here:\n",
    "\n",
    "    Data Science\n",
    "    Cross Validated — a statistics site\n",
    "    Artificial Intelligence\n",
    "    Mathematics\n",
    "    Stack Overflow\n",
    "\n",
    "And if we want to include Data Engineering, we can also consider:\n",
    "\n",
    "    Database Administrators;\n",
    "    Unix & Linux;\n",
    "    Software Engineering;\n",
    "\n",
    "If you open the link in the image shared above, you'll find a complete list of Stack Exchange websites sorted by percentage of questions that received answers. At the time of this writing, Data Science Stack Exchange (DSSE) is on the bottom 10 sites with respect to this metric.\n",
    "\n",
    "The fact that DSSE is a data science dedicated site (contrarily to the others), coupled with it having a lot of unanswered questions, makes it an ideal candidate for this investigation. DSSE will be the focus of this guided project.\n",
    "\n",
    "In this screen you'll be doing your first off-Dataquest exercise!\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. If you're not familiar with any Stack Exchange website, take the time to explore one of them. Try to answer a few of these questions in a markdown cell:\n",
    "- What kind of questions are welcome on this site?\n",
    "- What, other than questions, does the site's home subdivide into? Does any of them look useful towards our goal?\n",
    "- What information is available in each post?\n",
    "2. Explore some of the questions that were asked.\n",
    "3. Try asking a couple of questions on any of Stack Exchange sites to get a better feel for how the sites operate.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack Exchange Data Explorer <a name = \"sede\"></a>\n",
    "\n",
    "### Learn\n",
    "\n",
    "After a spending some time investigating the website, you decide that the tags will be very useful in categorizing content, saving you the trouble of you having to do it yourself.\n",
    "\n",
    "Now comes the challenge of accessing the data en masse. One potential solution would be to scrape the site. However, because we still haven't learned how to web scrape, and because we have an easier alternative (mostly the second reason), we're going to do something else.\n",
    "\n",
    "Stack Exchange provides a public data base for each of its websites. [Here's](https://data.stackexchange.com/datascience/query/new) a link to query and explore Data Science Stack Exchange's database.\n",
    "\n",
    "You can read more about Stack Exchange Data Explorer (SEDE) on its [help section](https://data.stackexchange.com/help) and on [this](https://data.stackexchange.com/tutorial) tutorial link.\n",
    "\n",
    "\n",
    "Note that SEDE uses a different dialect (Transact-SQL — Microsoft's SQL) than SQLite , which you learned earlier. Most things are the same, but some are different. For instance, the query below selects the top 10 results from a query.\n",
    "\n",
    "SELECT TOP 10 *\n",
    "\n",
    "  FROM tags\n",
    "\n",
    " ORDER BY Count DESC;\n",
    "\n",
    "In SQLite we would not only use the keyword LIMIT instead of TOP we would also included it at the end of the query, instead of in the SELECT statement. If you run into any issues due to these differences, try to research on your own how to solve them. Here's a helpful resource.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Explore Data Science Stack Exchange's data model.\n",
    "- Investigate a few of the tables, especially those whose names sound more promising;\n",
    "- Write a few queries to get a feel for the data;\n",
    "2. In a markdown cell, write about what tables look more promising towards finding the most popular content.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Data <a name = \"getting-data\"></a>\n",
    "\n",
    "### Learn\n",
    "\n",
    "The posts table has a lot of columns. We'll be focusing our attention on those that seem relevant towards our goal:\n",
    "\n",
    "    Id: An identification number for the post.\n",
    "\n",
    "    PostTypeId: An identification number for the type of post.\n",
    "\n",
    "    posttypes\n",
    "\n",
    "    CreationDate: The date and time of creation of the post.\n",
    "    Score: The post's score.\n",
    "    ViewCount: How many times the post was viewed.\n",
    "    Tags: What tags were used.\n",
    "    AnswerCount: How many answers the question got (only applicable to question posts).\n",
    "    FavoriteCount: How many times the question was favored (only applicable to question posts).\n",
    "\n",
    "Note that with the exception of the tags column, the last few columns contain information about how popular the post is — the kind of information we're after.\n",
    "\n",
    "There are eight different types of post. Before we try to figure out which of them are relevant to us, let's check how many of them there are:\n",
    "\n",
    "SELECT PostTypeId, COUNT(*) as NrOfPosts\n",
    "\n",
    "  FROM posts\n",
    "\n",
    " GROUP BY PostTypeId;\n",
    "\n",
    "PostTypeId \tNrOfPosts\n",
    "1 \t21446\n",
    "2 \t23673\n",
    "4 \t236\n",
    "5 \t236\n",
    "6 \t11\n",
    "7 \t1\n",
    "\n",
    "Due to their low volume, anything that isn't questions or answers is mostly inconsequential. Even if it happens to be the case that such kind of posts is immensely popular, they would just be outliers and not relevant to us. We'll then just focus on the questions.\n",
    "\n",
    "Since we're only interested in recent posts, we'll limit our analysis to the posts of 2019. (At the time of writing it is early 2020).\n",
    "\n",
    "The dataset we'll be using in this guided project is one resulting from a possible solution to the following exercise.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Run a query against the SEDE DSSE database that extracts the columns listed above for all the questions in 2019.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dependencies <a name=\"import-the-dependencies\"></a>\n",
    "We need to use the ... libraries within this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data <a name = \"exploring-data\"></a>\n",
    "\n",
    "## Learn\n",
    "\n",
    "The result of the query was stored in a file called 2019_questions.csv. Here are the first few rows of the data we got:\n",
    "\n",
    "Id,PostTypeId,CreationDate,Score,ViewCount,Tags,AnswerCount,FavoriteCount\n",
    "\n",
    "\"44419\",\"1\",\"2019-01-23 09:21:13\",\"1\",\"21\",\"<machine-learning><data-mining>\",\"0\",\"\"\n",
    "\n",
    "\"44420\",\"1\",\"2019-01-23 09:34:01\",\"0\",\"25\",\"<machine-learning><regression><linear-regression><regularization>\",\"0\",\"\"\n",
    "\n",
    "\"44423\",\"1\",\"2019-01-23 09:58:41\",\"2\",\"1651\",\"<python><time-series><forecast><forecasting>\",\"0\",\"\"\n",
    "\n",
    "\"44427\",\"1\",\"2019-01-23 10:57:09\",\"0\",\"55\",\"<machine-learning><scikit-learn><pca>\",\"1\",\"\"\n",
    "\n",
    "\"44428\",\"1\",\"2019-01-23 11:02:15\",\"0\",\"19\",\"<dataset><bigdata><data><speech-to-text>\",\"0\",\"\"\n",
    "\n",
    "Looking at the of each row, it stands out that FavouriteCount has missing values. What other issues are there with the data? Let's explore it.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. Read in the file into a dataframe.\n",
    "2. Explore the data. Try to answer a few of these questions in a markdown cell:\n",
    "- How many missing values are there in each column?\n",
    "- Can we fix the missing values somehow?\n",
    "- Are the types of each column adequate?\n",
    "- What can we do about the Tags column?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data <a name = \"cleaning-data\"></a>\n",
    "\n",
    "### Learn\n",
    "\n",
    "On the previous screen, we identified issues with the data. Fortunately for us, the folks at Stack Exchange did a great job of providing clean data. Let's fix the one issue we found, set the appropriate types for the columns, and clean the Tags column to fit our purposes.\n",
    "\n",
    "At the end of this screen, the types of the columns should be as follows.\n",
    "\n",
    "Id                        int64\n",
    "\n",
    "CreationDate     datetime64[ns]\n",
    "\n",
    "Score                     int64\n",
    "\n",
    "ViewCount                 int64\n",
    "\n",
    "Tags                     object\n",
    "\n",
    "AnswerCount               int64\n",
    "\n",
    "FavoriteCount             int64\n",
    "\n",
    "The values in the Tags column are strings that look like this:\n",
    "\n",
    "\"<machine-learning><regression><linear-regression><regularization>\"\n",
    "\n",
    "We'll want to transform this string in something more suitable to use typical string methods. Our goal will be to transform strings like the above in something like:\n",
    "\n",
    "\"machine-learning,regression,linear-regression,regularization\"\n",
    "\n",
    "We can then split on , to obtain a list.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Fill in the missing values with 0.\n",
    "2. Set the types of each column in accordance to what was illustrated above.\n",
    "3. Clean the Tags column and assign it back to itself:\n",
    "- Use the process illustrated above.\n",
    "- Assign the result to questions[\"Tags\"].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Used and Most Viewed <a name = \"most\"></a>\n",
    "\n",
    "### Learn\n",
    "\n",
    "We now focus on determining the most popular tags. We'll do so by considering two different popularity proxies: for each tag we'll count how many times the tag was used, and how many times a question with that tag was viewed.\n",
    "\n",
    "We could take into account the score, or whether or not a question is part of someone's favorite questions. These are all reasonable options to investigate; but we'll limit the focus of our research to counts and views for now.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Count how many times each tag was used.\n",
    "2. Count how many times each tag was viewed.\n",
    "3. Create visualizations for the top tags of each of the above results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relations Between Tags <a name = \"relations-tags\"></a>\n",
    "\n",
    "### Learn\n",
    "\n",
    "On this screen\n",
    "\n",
    "    most_used is a dataframe that counts how many times each of the top 20 tags was used.\n",
    "    most_viewed is a dataframe that counts how many times each of the top 20 tags was viewed.\n",
    "\n",
    "Looking at the results from the last exercise, we see that most top tags are present in both dataframes.\n",
    "\n",
    "Let's see what tags are in most_used, but not in most_viewed. We can identify them by the missing values in ViewCount below.\n",
    "\n",
    "in_used = pd.merge(most_used, most_viewed, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "\tCount \tViewCount\n",
    "machine-learning-model \t224 \tNaN\n",
    "statistics \t234 \tNaN\n",
    "clustering \t257 \t33928.0\n",
    "predictive-modeling \t265 \tNaN\n",
    "r \t268 \tNaN\n",
    "dataset \t340 \t43151.0\n",
    "regression \t347 \t49451.0\n",
    "pandas \t354 \t201787.0\n",
    "lstm \t402 \t74458.0\n",
    "time-series \t466 \t64134.0\n",
    "cnn \t489 \t70349.0\n",
    "nlp \t493 \t71382.0\n",
    "scikit-learn \t540 \t128110.0\n",
    "tensorflow \t584 \t121369.0\n",
    "classification \t685 \t104457.0\n",
    "keras \t935 \t268608.0\n",
    "neural-network \t1055 \t185367.0\n",
    "deep-learning \t1220 \t233628.0\n",
    "python \t1814 \t537585.0\n",
    "machine-learning \t2693 \t388499.0\n",
    "\n",
    "Similarly, let's see what tags are in the latter, but not the former:\n",
    "\n",
    "pd.merge(most_used, most_viewed, how=\"right\", left_index=True, right_index=True)\n",
    "\n",
    "\tCount \tViewCount\n",
    "clustering \t257.0 \t33928\n",
    "csv \tNaN \t38654\n",
    "pytorch \tNaN \t40240\n",
    "dataset \t340.0 \t43151\n",
    "regression \t347.0 \t49451\n",
    "numpy \tNaN \t49767\n",
    "time-series \t466.0 \t64134\n",
    "cnn \t489.0 \t70349\n",
    "nlp \t493.0 \t71382\n",
    "lstm \t402.0 \t74458\n",
    "dataframe \tNaN \t89352\n",
    "classification \t685.0 \t104457\n",
    "tensorflow \t584.0 \t121369\n",
    "scikit-learn \t540.0 \t128110\n",
    "neural-network \t1055.0 \t185367\n",
    "pandas \t354.0 \t201787\n",
    "deep-learning \t1220.0 \t233628\n",
    "keras \t935.0 \t268608\n",
    "machine-learning \t2693.0 \t388499\n",
    "python \t1814.0 \t537585\n",
    "\n",
    "The tags present in most_used and not present in most_viewed are:\n",
    "\n",
    "    machine-learning-model\n",
    "    statistics\n",
    "    predictive-modeling\n",
    "    r\n",
    "\n",
    "And the tags present in most_viewed but not in most_used are:\n",
    "\n",
    "    csv\n",
    "    pytorch\n",
    "    dataframe\n",
    "\n",
    "Some tags also stand out as being related. For example, python is related to pandas, as we can find both pythons and pandas in the same country — or better yet, because pandas is a Python library. So by writing about pandas, we can actually simultaneously tackle two tags.\n",
    "\n",
    "Other pairs of tags, shouldn't be related at all, like pandas and r:\n",
    "\n",
    "questions[questions[\"Tags\"].apply(\n",
    "\n",
    "    lambda tags: True if \"r\" in tags and \"pandas\" in tags else False)\n",
    "\n",
    "]\n",
    "\n",
    "\tId \tCreationDate \tScore \tViewCount \tTags \tAnswerCount \tFavoriteCount\n",
    "2873 \t60074 \t2019-09-11 20:35:17 \t0 \t22 \t[r, pandas, dplyr] \t0 \t0\n",
    "3651 \t49148 \t2019-04-11 19:41:39 \t1 \t83 \t[r, data-mining, pandas, matlab, databases] \t3 \t0\n",
    "\n",
    "Just two results. You can look at these questions by replacing ID in https://datascience.stackexchange.com/questions/ID with the questions' Ids values and see what they are about.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "The goal of this exercise is to make you think about technical solutions to determining how tags are related. We haven't covered any techniques to deal with this yet, so don't worry if nothing comes to mind.\n",
    "\n",
    "1. Brainstorm some ways in which you could find relationships between pair of tags.\n",
    "2. Brainstorm some ways in which you could find relationships between multiple tags.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter Domain Knowledge <a name = \"enter-domain\"></a>\n",
    "\n",
    "### Learn\n",
    "\n",
    "Although analytical solutions to the problem set forth in the previous screen exist, they aren't necessarily needed, nor the best way to go about solving the problem.\n",
    "\n",
    "Domain knowledge can be very useful. Let's see how it can help us here.\n",
    "\n",
    "You may have noticed that the most used tags are also the most viewed. From the top 10 tags of each, here's a list of the tags in common: python, machine-learning, deep-learning, neural-network, keras, tensorflow, classification, scikit-learn.\n",
    "\n",
    "Do you know what each of these or most of these tags means? Could there be strong relations between them?\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Take a look at the tags page on DSSE. Try to answer the questions above. Do additional research on the internet as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just a Fad? <a name = \"just-fad\"></a>\n",
    "\n",
    "### Learn\n",
    "\n",
    "Before we officially make our recommendation, it would be nice to solidify our findings with additional proof. More specifically, one thing that comes to mind is \"Is deep learning just a fad?\" Ideally, the content we decide to create will be the most useful for as long as possible. Could interest in deep learning be slowing down? Back to SEDE!\n",
    "\n",
    "The file all_questions.csv holds the result of the query below — this query fetches all of the questions ever asked on DSSE, their dates and tags.\n",
    "\n",
    "SELECT Id, CreationDate, Tags\n",
    "\n",
    "  FROM posts\n",
    "\n",
    " WHERE PostTypeId = 1;\n",
    "\n",
    "In this we will track the interest in deep learning across time. We will:\n",
    "\n",
    "    Count how many deep learning questions are asked per time period.\n",
    "    The total amount of questions per time period.\n",
    "    How many deep learning questions there are relative to the total amount of questions per time period.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Read the file all_questions.csv into a dataframe.\n",
    "2. Transform the tags column in a similar manner to what was previously done.\n",
    "3. Think about what questions should be classified as deep learning questions and the implement that definition.\n",
    "4. Decide on an adequate timeframe and track interest in deep learning across that timeframe:\n",
    "- Count how many deep learning questions are asked per time period.\n",
    "- The total amount of questions per time period.\n",
    "- How many deep learning questions there are relative to the total amount of questions per time period;\n",
    "- Write your observations and final recommendation in a markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps <a name = \"next-steps\"></a>\n",
    "\n",
    "### Learn\n",
    "\n",
    "Our work allowed us to conclude that deep learning is the most popular topic right now. Here are some things to consider:\n",
    "\n",
    "- What other content can we recommend that isn't as popular? You can try using association rules to find strong relations between tags.\n",
    "- What other popularity features could we include in our analysis? Perhaps scores and favourite counts?\n",
    "- We focused on DSSE. How could we use other related sites to help us with our goal?\n",
    "- How can we leverage other sites to determine what non-data-science content to write about? For example, is there some mathematical field that leads to more questions than others?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-lda",
   "language": "python",
   "name": "venv-lda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
