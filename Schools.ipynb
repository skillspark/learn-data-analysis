{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Project: Analyzing NYC High School Data\n",
    "\n",
    "## Introduction\n",
    "This is a guided project I completed on the [Dataquest](https://app.dataquest.io)  learning platform. \n",
    "The focus of this project was to learn new skills related to the data cleansing workflow. The goals are to cleanse and merge the available public data sets as well as to start investigating any correlations between the SAT Scores and other factors apparent from New York City public schools.\n",
    "The code is written in Python, using pandas, numpy and re libraries, and is shown in Jupyter Notebooks.\n",
    "\n",
    "To run these notebooks:\n",
    "1. Download all the required public data sets (see below)\n",
    "2. Open the .ipynb files in this repository using your favourite tool for Notebooks\n",
    "\n",
    "The public data sets used are available from the following sources:\n",
    "-  [student SAT scores](https://data.cityofnewyork.us/Education/SAT-Results/f9bf-2cp4) by high school\n",
    "- [School attendance](https://data.cityofnewyork.us/Education/School-Attendance-and-Enrollment-Statistics-by-Dis/7z8d-msnt) - Attendance information for each school in New York City\n",
    "- [Class size](https://data.cityofnewyork.us/Education/2010-2011-Class-Size-School-level-detail/urz7-pzb3) - Information on class size for each school\n",
    "- [AP test results](https://data.cityofnewyork.us/Education/AP-College-Board-2010-School-Level-Results/itfs-ms3e) - Advanced Placement (AP) exam results for each high school (passing an optional AP exam in a particular subject can earn a student college credit in that subject)\n",
    "- [Graduation outcomes](https://data.cityofnewyork.us/Education/Graduation-Outcomes-Classes-Of-2005-2010-School-Le/vh2h-md7a) - The percentage of students who graduated and other outcome information\n",
    "- [Demographics](https://data.cityofnewyork.us/Education/School-Demographics-and-Accountability-Snapshot-20/ihfw-zy9j) - Demographic information for each school\n",
    "- [School survey](https://data.cityofnewyork.us/Education/NYC-School-Survey-2011/mnz3-dyi8) - Surveys of parents, teachers, and students at each school"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import re\n",
    "\n",
    "data_files = [\n",
    "    \"ap_2010.csv\",\n",
    "    \"class_size.csv\",\n",
    "    \"demographics.csv\",\n",
    "    \"graduation.csv\",\n",
    "    \"hs_directory.csv\",\n",
    "    \"sat_results.csv\"\n",
    "]\n",
    "\n",
    "data = {}\n",
    "\n",
    "for f in data_files:\n",
    "    d = pd.read_csv(\"data/schools/{0}\".format(f))\n",
    "    data[f.replace(\".csv\", \"\")] = d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_131056/1811195328.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  survey[\"DBN\"] = survey[\"dbn\"]\n"
     ]
    }
   ],
   "source": [
    "all_survey = pd.read_csv(\"data/schools/survey_all.txt\", delimiter=\"\\t\", encoding='windows-1252')\n",
    "d75_survey = pd.read_csv(\"data/schools/survey_d75.txt\", delimiter=\"\\t\", encoding='windows-1252')\n",
    "survey = pd.concat([all_survey, d75_survey], axis=0)\n",
    "\n",
    "survey[\"DBN\"] = survey[\"dbn\"]\n",
    "\n",
    "survey_fields = [\n",
    "    \"DBN\", \n",
    "    \"rr_s\", \n",
    "    \"rr_t\", \n",
    "    \"rr_p\", \n",
    "    \"N_s\", \n",
    "    \"N_t\", \n",
    "    \"N_p\", \n",
    "    \"saf_p_11\", \n",
    "    \"com_p_11\", \n",
    "    \"eng_p_11\", \n",
    "    \"aca_p_11\", \n",
    "    \"saf_t_11\", \n",
    "    \"com_t_11\", \n",
    "    \"eng_t_11\", \n",
    "    \"aca_t_11\", \n",
    "    \"saf_s_11\", \n",
    "    \"com_s_11\", \n",
    "    \"eng_s_11\", \n",
    "    \"aca_s_11\", \n",
    "    \"saf_tot_11\", \n",
    "    \"com_tot_11\", \n",
    "    \"eng_tot_11\", \n",
    "    \"aca_tot_11\",\n",
    "]\n",
    "survey = survey.loc[:,survey_fields]\n",
    "data[\"survey\"] = survey"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add DBN columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"hs_directory\"][\"DBN\"] = data[\"hs_directory\"][\"dbn\"]\n",
    "\n",
    "def pad_csd(num):\n",
    "    string_representation = str(num)\n",
    "    if len(string_representation) > 1:\n",
    "        return string_representation\n",
    "    else:\n",
    "        return \"0\" + string_representation\n",
    "    \n",
    "data[\"class_size\"][\"padded_csd\"] = data[\"class_size\"][\"CSD\"].apply(pad_csd)\n",
    "data[\"class_size\"][\"DBN\"] = data[\"class_size\"][\"padded_csd\"] + data[\"class_size\"][\"SCHOOL CODE\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert columns to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['SAT Math Avg. Score', 'SAT Critical Reading Avg. Score', 'SAT Writing Avg. Score']\n",
    "for c in cols:\n",
    "    data[\"sat_results\"][c] = pd.to_numeric(data[\"sat_results\"][c], errors=\"coerce\")\n",
    "\n",
    "data['sat_results']['sat_score'] = data['sat_results'][cols[0]] + data['sat_results'][cols[1]] + data['sat_results'][cols[2]]\n",
    "\n",
    "def find_lat(loc):\n",
    "    coords = re.findall(\"\\(.+, .+\\)\", loc)\n",
    "    lat = coords[0].split(\",\")[0].replace(\"(\", \"\")\n",
    "    return lat\n",
    "\n",
    "def find_lon(loc):\n",
    "    coords = re.findall(\"\\(.+, .+\\)\", loc)\n",
    "    lon = coords[0].split(\",\")[1].replace(\")\", \"\").strip()\n",
    "    return lon\n",
    "\n",
    "data[\"hs_directory\"][\"lat\"] = data[\"hs_directory\"][\"Location 1\"].apply(find_lat)\n",
    "data[\"hs_directory\"][\"lon\"] = data[\"hs_directory\"][\"Location 1\"].apply(find_lon)\n",
    "\n",
    "data[\"hs_directory\"][\"lat\"] = pd.to_numeric(data[\"hs_directory\"][\"lat\"], errors=\"coerce\")\n",
    "data[\"hs_directory\"][\"lon\"] = pd.to_numeric(data[\"hs_directory\"][\"lon\"], errors=\"coerce\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condense datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size = data[\"class_size\"]\n",
    "class_size = class_size[class_size[\"GRADE \"] == \"09-12\"]\n",
    "class_size = class_size[class_size[\"PROGRAM TYPE\"] == \"GEN ED\"]\n",
    "\n",
    "# works on pandas 1\n",
    "# class_size = class_size.groupby(\"DBN\").agg(numpy.mean) \n",
    "#  works on pandas 2\n",
    "class_size = class_size.groupby(\"DBN\").mean(numeric_only=True)\n",
    "class_size.reset_index(inplace=True)\n",
    "data[\"class_size\"] = class_size\n",
    "\n",
    "data[\"demographics\"] = data[\"demographics\"][data[\"demographics\"][\"schoolyear\"] == 20112012]\n",
    "\n",
    "data[\"graduation\"] = data[\"graduation\"][data[\"graduation\"][\"Cohort\"] == \"2006\"]\n",
    "data[\"graduation\"] = data[\"graduation\"][data[\"graduation\"][\"Demographic\"] == \"Total Cohort\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert AP scores to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['AP Test Takers ', 'Total Exams Taken', 'Number of Exams with scores 3 4 or 5']\n",
    "\n",
    "for col in cols:\n",
    "    data[\"ap_2010\"][col] = pd.to_numeric(data[\"ap_2010\"][col], errors=\"coerce\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_size\n",
      "demographics\n",
      "survey\n",
      "hs_directory\n"
     ]
    }
   ],
   "source": [
    "combined = data[\"sat_results\"]\n",
    "\n",
    "combined = combined.merge(data[\"ap_2010\"], on=\"DBN\", how=\"left\")\n",
    "combined = combined.merge(data[\"graduation\"], on=\"DBN\", how=\"left\")\n",
    "\n",
    "to_merge = [\n",
    "            \"class_size\", \n",
    "            \"demographics\", \n",
    "            \"survey\", \n",
    "            \"hs_directory\"\n",
    "            ]\n",
    "\n",
    "for m in to_merge:\n",
    "    combined = combined.merge(data[m], on=\"DBN\", how=\"inner\")\n",
    "\n",
    "combined = combined.fillna(combined.mean(numeric_only=True))\n",
    "combined = combined.fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a school district column for mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_131056/1203636352.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined[\"school_dist\"] = combined[\"DBN\"].apply(get_first_two_chars)\n"
     ]
    }
   ],
   "source": [
    "def get_first_two_chars(dbn):\n",
    "    return dbn[0:2]\n",
    "\n",
    "combined[\"school_dist\"] = combined[\"DBN\"].apply(get_first_two_chars)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '01M292'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m correlations \u001b[39m=\u001b[39m combined\u001b[39m.\u001b[39;49mcorr()\n\u001b[1;32m      2\u001b[0m correlations \u001b[39m=\u001b[39m correlations[\u001b[39m\"\u001b[39m\u001b[39msat_score\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(correlations)\n",
      "File \u001b[0;32m~/Documents/dev/learn-data-analysis/venv-lda/lib/python3.10/site-packages/pandas/core/frame.py:10054\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  10052\u001b[0m cols \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m  10053\u001b[0m idx \u001b[39m=\u001b[39m cols\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m> 10054\u001b[0m mat \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mto_numpy(dtype\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m, na_value\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mnan, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m  10056\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpearson\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m  10057\u001b[0m     correl \u001b[39m=\u001b[39m libalgos\u001b[39m.\u001b[39mnancorr(mat, minp\u001b[39m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m~/Documents/dev/learn-data-analysis/venv-lda/lib/python3.10/site-packages/pandas/core/frame.py:1838\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1836\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1837\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1838\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   1839\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m dtype:\n\u001b[1;32m   1840\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(result, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/dev/learn-data-analysis/venv-lda/lib/python3.10/site-packages/pandas/core/internals/managers.py:1732\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1730\u001b[0m         arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1732\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   1733\u001b[0m     \u001b[39m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1734\u001b[0m     \u001b[39m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1736\u001b[0m \u001b[39mif\u001b[39;00m na_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n",
      "File \u001b[0;32m~/Documents/dev/learn-data-analysis/venv-lda/lib/python3.10/site-packages/pandas/core/internals/managers.py:1794\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1792\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1793\u001b[0m         arr \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1794\u001b[0m     result[rl\u001b[39m.\u001b[39;49mindexer] \u001b[39m=\u001b[39m arr\n\u001b[1;32m   1795\u001b[0m     itemmask[rl\u001b[39m.\u001b[39mindexer] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1797\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m itemmask\u001b[39m.\u001b[39mall():\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '01M292'"
     ]
    }
   ],
   "source": [
    "correlations = combined.corr()\n",
    "correlations = correlations[\"sat_score\"]\n",
    "print(correlations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting survey correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Remove DBN since it's a unique identifier, not a useful numerical value for correlation.\n",
    "survey_fields.remove(\"DBN\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Safety and SAT Scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate safety scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a scatter plot of the saf_s_11 column vs. the sat_score in combined. \n",
    "combined.plot(kind=\"scatter\", x=\"sat_score\", y=\"saf_s_11\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion about Safety\n",
    "There seems to be a strong positive correlation between Safety and SAT Scores. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute safety scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average safety score for each borough.\n",
    "boro_saft_avg = combined.groupby(\"boro\")[\"saf_s_11\"].mean()\n",
    "print(boro_saft_avg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion about Safety Scores\n",
    "The schools in the borough of Brooklyn scores the lowest average safety score, while the schools in the borough of Manhattan scores the highest average safety scores."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Race and SAT Scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate racial differences in SAT scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bar plot of the correlations between the race percentage and sat_score\n",
    "race_scor_cols = [\"white_per\", \"asian_per\", \"black_per\"]\n",
    "combined.corr()[\"sat_score\"][race_scor_cols].plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion about correlation of racial differences and SAT scores\n",
    "For the correlation between the race of the students and the SAT scores, there appears to be rather strong positive correlations for white and asian. For black, there is a weak negative correlation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore schools with low SAT scores and high values for hispanic_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a scatter plot of the hispanic_per vs. the sat_score in combined. \n",
    "combined.plot(kind=\"scatter\", x=\"sat_score\", y=\"hispanic_per\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion about observation of scatter plot: hispanic percentage vs. SAT scores\n",
    "When the SAT Scores are above around 1500, there appears to be strong negative correlation with hispanic attendees. To confirm, create a scatterplot with SAT scores only above 1500 to check this observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# limit to scores above 1500 and create a new scatterplot\n",
    "combined_gt_1500 = combined[combined[\"sat_score\"]>1600]\n",
    "combined_gt_1500.plot(kind=\"scatter\", x=\"sat_score\", y=\"hispanic_per\")\n",
    "print(\"The r-value for the correlation between sat_score and hispanic_per is:\")\n",
    "combined_gt_1500.corr()[\"sat_score\"][\"hispanic_per\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research any schools with a hispanic_per greater than 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the data for >95%\n",
    "combined_hisp_gt_95 = combined[combined[\"hispanic_per\"] > 95]\n",
    "print(combined_hisp_gt_95[\"SCHOOL NAME\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations about these schools\n",
    "These schools seem to be aimed towards Spanish-speaking students from Latin American backgrounds.\n",
    "Also, the schools are not consistently represented on Wikipedia. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research any schools with a hispanic_per less than 10% and an average SAT score greater than 1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_hisp_lt_10 = combined[combined[\"hispanic_per\"] < 10]\n",
    "combined_hisp_lt_10_ss_gt_1800 = combined_hisp_lt_10[combined_hisp_lt_10[\"sat_score\"] > 1800]\n",
    "print(combined_hisp_lt_10_ss_gt_1800[\"SCHOOL NAME\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations about these schools\n",
    "These schools seem to be high in demand, with only about 3% of applications accepted. This indicates that they are on average accepting less than 10% Hispanic students, and on average accepting students with SAT scores higher than 1800.\n",
    "Also, the schools are consistently represented on Wikipedia. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Gender and SAT Scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate gender differences in SAT scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bar plot of the correlations between the gender and sat_score\n",
    "gender_scor_cols = [\"male_per\", \"female_per\"]\n",
    "combined.corr()[\"sat_score\"][gender_scor_cols].plot.bar()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations about the genders\n",
    "It appears like there are weak postive and negative correlations with SAT scores for male and female student percentages, respectively."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Exploring AP Scores vs. SAT Scores\n",
    "\n",
    "## Percentage students in each school taking an AP exam\n",
    "Correlate this AP percentage with the SAT Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the ap_per and add as a new column to the dataset\n",
    "combined[\"ap_per\"] = (combined[\"AP Test Takers \"] / combined[\"total_enrollment\"])*100\n",
    "# draw a scatter plot\n",
    "combined.plot(kind=\"scatter\", x=\"sat_score\", y=\"ap_per\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations about the relationship between AP scores and SAT scores\n",
    "From the chart above it appears that there is no observable relationship between AP Scores and SAT Scores over the whole dataset. However, there is a quite strong positive correlation when looking only at those who scored above 1300 for the SAT Score. See the enhanced scatter plot below.  \n",
    "Also, from the chart above, what is interesting, is there is a almost perfect vertical linear relationship with AP scores where the SAT Score is just above 1200. This could indicate that there is a requirement to take the AP Test if the SAT score is equal to a certain number around 1200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit to scores above 1300 and create a new scatterplot\n",
    "combined_gt_1300 = combined[combined[\"sat_score\"]>1300]\n",
    "combined_gt_1300.plot(kind=\"scatter\", x=\"sat_score\", y=\"ap_per\")\n",
    "print(\"The r-value for the correlation between sat_score > 1300 and ap_per is:\")\n",
    "combined_gt_1300.corr()[\"sat_score\"][\"ap_per\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-lda",
   "language": "python",
   "name": "venv-lda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
